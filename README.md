# ğŸ¯ Unified XAI Interface

**Multi-Modal Classification with Explainable AI**

A comprehensive web application integrating deepfake audio detection and lung cancer detection with explainable AI techniques (LIME). Built with Flask, PyTorch, and modern web technologies.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Models & XAI](#models--xai)
- [Documentation](#documentation)
- [Team](#team)
- [License](#license)

---

## ğŸ¯ Overview

This project implements a unified interface for two distinct classification tasks:

1. **Audio Classification**: Deepfake detection (Real vs Fake speech)

- **Models:** VGG16, MobileNet, ResNet, Custom CNN
- **Dataset:** Fake-or-Real (FoR) Dataset
- **Input:** `.wav` audio files
- **XAI Methods:** LIME, SHAP

2. **Image Classification**: Chest X-ray analysis (Normal vs Malignant)

- **Models:** AlexNet, DenseNet
- **Dataset:** CheXpert chest X-rays
- **Input:** `.png`, `.jpg` image files
- **XAI Methods:** Grad-CAM, LIME, SHAP

Both models are enhanced with **LIME** (Local Interpretable Model-agnostic Explanations) to provide visual explanations of predictions, making the AI decision-making process transparent and interpretable.

### Key Objectives

- âœ… Unified interface for multi-modal inputs
- âœ… Explainable AI integration
- âœ… Automatic compatibility filtering
- âœ… Professional web interface
- âœ… Modular, extensible architecture

---

## âœ¨ Features

### ğŸ¨ Web Interface (Flask)
- **Beautiful Modern UI** - Gradient design with smooth animations
- **Drag & Drop Upload** - Intuitive file upload
- **Real-time Processing** - Live progress updates
- **Responsive Design** - Works on all devices
- **Toast Notifications** - Clear user feedback

### ğŸ§  Machine Learning
- **CustomCNN** - Lightweight audio classification model
- **AlexNet** - Transfer learning for medical imaging
- **Dual Modality** - Handles both audio and images
- **CPU Support** - No GPU required (Colab optional)

### ğŸ” Explainable AI
- **LIME Integration** - Visual feature importance
- **Automatic Filtering** - XAI method compatibility checking
- **Clear Visualizations** - Heatmaps and overlays
- **Interpretable Results** - Understand model decisions

### ğŸ“Š Additional Features
- Session management
- File validation
- Automatic preprocessing
- Confidence scores
- Probability visualization

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Virtual environment (recommended)

### Step 1: Clone the Repository

```bash
git clone https://github.com/lisacharuel/XAI_Final_Project.git
cd XAI_Final_Project
```

### Step 2: Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Add Sample Data

Download the sample data and place files in:
```
data/
â”œâ”€â”€ sample_audio/
â”‚   â”œâ”€â”€ real_speech_1.wav
â”‚   â”œâ”€â”€ real_speech_2.wav
â”‚   â”œâ”€â”€ fake_speech_1.wav
â”‚   â””â”€â”€ fake_speech_2.wav
â””â”€â”€ sample_images/
    â”œâ”€â”€ normal_xray_1.png
    â”œâ”€â”€ normal_xray_2.png
    â”œâ”€â”€ malignant_xray_1.png
    â””â”€â”€ malignant_xray_2.png
```

---

## ğŸ® Usage

### Launch Flask Application

```bash
python app_flask.py
```

The application will start on **http://localhost:5000**

### Using the Interface

1. **Upload File**
   - Drag & drop or click to browse
   - Supports: `.wav`, `.mp3`, `.jpg`, `.png`
   - Max size: 10MB

2. **Select Model**
   - Click on the appropriate model button
   - CustomCNN for audio
   - AlexNet for images

3. **View Prediction**
   - See classification result
   - View confidence score
   - Examine probability distribution

4. **Generate Explanation**
   - Click "Explain with LIME"
   - Wait 30-60 seconds for processing
   - View visual explanation

5. **Reset** (Optional)
   - Click reset button to start over

### Alternative: Chainlit Interface

A chat-based interface is also available:

```bash
chainlit run app.py -w --port 8080
```

Access at **http://localhost:8080**

---

## ğŸ“ Project Structure

```
XAI_Final_Project/
â”œâ”€â”€ app_flask.py              # Flask web application (MAIN)
â”œâ”€â”€ app.py                    # Chainlit interface (alternative)
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ models/                   # Neural network models
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â””â”€â”€ custom_cnn_audio.py
â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â””â”€â”€ alexnet_image.py
â”‚   â””â”€â”€ model_loader.py
â”‚
â”œâ”€â”€ preprocessing/            # Data preprocessing
â”‚   â”œâ”€â”€ audio_processor.py
â”‚   â””â”€â”€ image_processor.py
â”‚
â”œâ”€â”€ xai/                      # Explainable AI
â”‚   â””â”€â”€ lime_explainer.py
â”‚
â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”œâ”€â”€ file_handler.py
â”‚   â””â”€â”€ compatibility_checker.py
â”‚
â”œâ”€â”€ templates/                # Flask HTML templates
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ static/                   # CSS and JavaScript
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js
â”‚
â”œâ”€â”€ data/                     # Sample data (not in git)
â”‚   â”œâ”€â”€ sample_audio/
â”‚   â””â”€â”€ sample_images/
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ TECHNICAL_REPORT.md
â”‚   â””â”€â”€ GENERATIVE_AI_USAGE.md
â”‚
â””â”€â”€ outputs/                  # Generated visualizations
    â””â”€â”€ visualizations/
```

---

## ğŸ§  Models & XAI

### Audio Model: CustomCNN

**Architecture:**
- 3 Convolutional blocks (Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool)
- Global Average Pooling
- 2 Fully Connected layers
- Dropout regularization

**Input:** Mel-spectrogram (3, 128, 128)  
**Output:** Binary classification (Real/Fake)  
**Parameters:** ~200K

### Image Model: AlexNet

**Architecture:**
- 5 Convolutional layers
- 3 Fully Connected layers
- Transfer learning from ImageNet
- Modified final layer for binary classification

**Input:** RGB image (3, 224, 224)  
**Output:** Binary classification (Normal/Malignant)  
**Parameters:** ~60M

### XAI Method: LIME

**Local Interpretable Model-agnostic Explanations**

- Generates 1000 perturbed samples
- Fits local linear model
- Identifies important features
- Creates visual heatmaps
- Works for both audio and images

---

## ğŸ“š Documentation

Comprehensive documentation is available in the `docs/` folder:

- **[TECHNICAL_REPORT.md](docs/TECHNICAL_REPORT.md)** - Detailed technical documentation
- **[GENERATIVE_AI_USAGE.md](docs/GENERATIVE_AI_USAGE.md)** - AI tools disclosure
- **[DEMO_GUIDE.md](docs/DEMO_GUIDE.md)** - Presentation guide

---

## ğŸ‘¥ Team

**Project:** Unified XAI Interface  
**Course:** Explainability AI 

**Team Members:**
- Lisa CHARUEL
- Aymeric MARTIN
- Julien DE VOS

---

## ğŸ› ï¸ Technologies Used

### Backend
- **Python 3.8+** - Programming language
- **PyTorch 2.0+** - Deep learning framework
- **Flask 3.0+** - Web framework
- **LIME** - Explainable AI library

### Audio Processing
- **librosa** - Audio analysis
- **soundfile** - Audio I/O
- **scipy** - Signal processing

### Image Processing
- **torchvision** - Image preprocessing
- **PIL** - Image handling
- **scikit-image** - Image segmentation

### Frontend
- **HTML5/CSS3** - Modern web standards
- **JavaScript (Vanilla)** - Interactive UI
- **Inter Font** - Typography

---

## âš™ï¸ Configuration

### Change Port

Edit `app_flask.py`:
```python
app.run(host='0.0.0.0', port=5001, debug=True)
```

### Adjust File Size Limit

Edit `app_flask.py`:
```python
app.config['MAX_CONTENT_LENGTH'] = 20 * 1024 * 1024  # 20MB
```

### Modify LIME Parameters

Edit `xai/lime_explainer.py`:
```python
self.num_samples = 1000  # Number of samples
self.num_features = 10   # Top features to show
```

---

## ğŸ› Troubleshooting

### Port Already in Use
```bash
# Use different port
# Edit app_flask.py or:
python app_flask.py  # Then change port in file
```

### Module Not Found
```bash
pip install -r requirements.txt
```

### LIME Takes Too Long
Reduce samples in `xai/lime_explainer.py`:
```python
self.num_samples = 500  # Faster but less accurate
```

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Anthropic** - Claude AI and Gemini for development assistance
- **PyTorch Team** - Deep learning framework
- **LIME Authors** - Explainable AI methodology
- **Flask Community** - Web framework
- **Course Instructors** - Project guidance

---


## ğŸ¯ Project Status

- âœ… Phase 1: Project Foundation
- âœ… Phase 2: Model Implementation
- âœ… Phase 3: XAI Integration
- âœ… Phase 4: Web Interface (Flask)
- âœ… Phase 5: Documentation & Testing


---

